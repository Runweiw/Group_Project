---
title: "506_project_Flexmix"
author: "Lingke Ying"
date: "11/27/2018"
output:
  html_document: default
  pdf_document: default
---

In this section we will use the package flexmix to fit finite mixtures of regression models. flexmix implements a general framework for fitting discrete mixtures of regression models in the R statistical computing environment. 

General information
```{r general, message = FALSE}
library(flexmix)
library(dplyr)
# m1 - S4 object, use @ to retrieve the attributes
```

We first download Wine dataset from the UCI Machine Learning Repository and save the dataset to the current working directory.

```{r dataset}
wine <- read.delim("~/wine.txt", sep = ",")
a = c("Class", "Alcohol", "Malic_acid", "Ash", "Alcalinity_of_ash", "Magnesium", 
      "Total_phenols", "Flavanoids", "Nonflavanoid_phenols", "Proanthocyanins", 
      "Color_intensity", "Hue", "OD280/OD315_of_diluted_wines", "Proline")
names(wine) <- t(a)
```

Then we explore the patterns of variables. 
We plot below the density plot of response “Color_intensity", the density plot of predictor “Total_phenols", and the histogram of the ground truth class “Class”).

```{r pattern}
# - density plot of response “Color_intensity”
d_color <- density(wine$Color_intensity)
plot(d_color, main="Density of Color_intensity")
# - density plot of predictor “Total_phenols”
d_phenol <- density(wine$Total_phenols)
plot(d_phenol, main="Density of Total_phenols")
# - histogram of the ground truth class “Class”
h_class <- hist(wine$Class)
```

We want to set the initial values for EM iterations.

Results of model fitting are shown below:
```{r results}
m1 = flexmix(Color_intensity ~ Total_phenols, data = wine, k = 3)
print(summary(m1))
print(parameters(m1))
```
6. We then did clustering and classification:
```{r cluster}
Cluster = m1@cluster
post = m1@posterior$scaled

for (i in 1:177){
  if(Cluster[i] == 2){return(1)}
  if(Cluster[i] == 3){return(2)}
  if(Cluster[i] == 1){return(3)}
}

Cluster
```

8. We calculate the accuracy of the classification and create a confusion matrix.
```{r error}
# Error rate
Class = wine$Class
accuracy = sum(Class != Cluster)/178
print(accuracy)
# Confusion matrix
C_mat = table(Cluster, wine$Class)
knitr::kable(C_mat, align = 'c', caption = 'confusion_matrix') 

```

